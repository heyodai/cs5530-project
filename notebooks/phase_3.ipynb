{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3 - Model Training and Evaluation\n",
    "\n",
    "Goals for this phase:\n",
    "\n",
    "1. Split the dataset into training, validation, and test sets.\n",
    "2. Train the model on the training set and monitor its performance on the validation set. \n",
    "3. Evaluate the model on the test set to get a final estimate of its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load libraries and dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from transformers import AlbertTokenizer, AlbertModel\n",
    "from transformers import ElectraTokenizer, ElectraModel\n",
    "# from transformers import TinyBertTokenizer, TinyBertModel\n",
    "from transformers import MobileBertTokenizer, MobileBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Content</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Summary_Tokens</th>\n",
       "      <th>Content_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f49ee725a0360aa6881ed1f7999cc531885dd06a</td>\n",
       "      <td>New York police are concerned drones could bec...</td>\n",
       "      <td>Police have investigated criminals who have ri...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "      <td>['Police', 'have', 'investigated', 'criminal',...</td>\n",
       "      <td>['New', 'York', 'police', 'are', 'concerned', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>808fe317a53fbd3130c9b7563341a7eea6d15e94</td>\n",
       "      <td>By . Ryan Lipman . Perhaps Australian porn sta...</td>\n",
       "      <td>Porn star Angela White secretly filmed sex act...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "      <td>['Porn', 'star', 'Angela', 'White', 'secretly'...</td>\n",
       "      <td>['By', '.', 'Ryan', 'Lipman', '.', 'Perhaps', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98fd67bd343e58bc4e275bbb5a4ea454ec827c0d</td>\n",
       "      <td>This was, Sergio Garcia conceded, much like be...</td>\n",
       "      <td>American draws inspiration from fellow country...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "      <td>['American', 'draw', 'inspiration', 'from', 'f...</td>\n",
       "      <td>['This', 'was,', 'Sergio', 'Garcia', 'conceded...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e12b5bd7056287049d9ec98e41dbb287bd19a981</td>\n",
       "      <td>An Ebola outbreak that began in Guinea four mo...</td>\n",
       "      <td>World Health Organisation: 635 infections and ...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "      <td>['World', 'Health', 'Organisation:', '635', 'i...</td>\n",
       "      <td>['An', 'Ebola', 'outbreak', 'that', 'began', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b83e8bcfcd51419849160e789b6658b21a9aedcd</td>\n",
       "      <td>By . Associated Press and Daily Mail Reporter ...</td>\n",
       "      <td>A sinkhole opened up at 5:15am this morning in...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "      <td>['A', 'sinkhole', 'opened', 'up', 'at', '5:15a...</td>\n",
       "      <td>['By', '.', 'Associated', 'Press', 'and', 'Dai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         ID   \n",
       "0  f49ee725a0360aa6881ed1f7999cc531885dd06a  \\\n",
       "1  808fe317a53fbd3130c9b7563341a7eea6d15e94   \n",
       "2  98fd67bd343e58bc4e275bbb5a4ea454ec827c0d   \n",
       "3  e12b5bd7056287049d9ec98e41dbb287bd19a981   \n",
       "4  b83e8bcfcd51419849160e789b6658b21a9aedcd   \n",
       "\n",
       "                                             Content   \n",
       "0  New York police are concerned drones could bec...  \\\n",
       "1  By . Ryan Lipman . Perhaps Australian porn sta...   \n",
       "2  This was, Sergio Garcia conceded, much like be...   \n",
       "3  An Ebola outbreak that began in Guinea four mo...   \n",
       "4  By . Associated Press and Daily Mail Reporter ...   \n",
       "\n",
       "                                             Summary         Dataset   \n",
       "0  Police have investigated criminals who have ri...  CNN/Daily Mail  \\\n",
       "1  Porn star Angela White secretly filmed sex act...  CNN/Daily Mail   \n",
       "2  American draws inspiration from fellow country...  CNN/Daily Mail   \n",
       "3  World Health Organisation: 635 infections and ...  CNN/Daily Mail   \n",
       "4  A sinkhole opened up at 5:15am this morning in...  CNN/Daily Mail   \n",
       "\n",
       "                                      Summary_Tokens   \n",
       "0  ['Police', 'have', 'investigated', 'criminal',...  \\\n",
       "1  ['Porn', 'star', 'Angela', 'White', 'secretly'...   \n",
       "2  ['American', 'draw', 'inspiration', 'from', 'f...   \n",
       "3  ['World', 'Health', 'Organisation:', '635', 'i...   \n",
       "4  ['A', 'sinkhole', 'opened', 'up', 'at', '5:15a...   \n",
       "\n",
       "                                      Content_Tokens  \n",
       "0  ['New', 'York', 'police', 'are', 'concerned', ...  \n",
       "1  ['By', '.', 'Ryan', 'Lipman', '.', 'Perhaps', ...  \n",
       "2  ['This', 'was,', 'Sergio', 'Garcia', 'conceded...  \n",
       "3  ['An', 'Ebola', 'outbreak', 'that', 'began', '...  \n",
       "4  ['By', '.', 'Associated', 'Press', 'and', 'Dai...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Load the cleaned dataset\n",
    "df = pd.read_csv('../data/cleaned.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Split the dataset\n",
    "train_df = df.sample(frac=0.8, random_state=42)\n",
    "test_df = df.drop(train_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define a function to prepare the input for the models\n",
    "def prepare_input(tokens, max_length, tokenizer):\n",
    "    # Prepare the input for the model\n",
    "    encoded_dict = tokenizer.encode_plus(tokens, max_length=max_length, \n",
    "                                          padding='max_length', truncation=True, \n",
    "                                          return_tensors='pt')\n",
    "    return {'input_ids': encoded_dict['input_ids'],\n",
    "            'attention_mask': encoded_dict['attention_mask']}\n",
    "# def prepare_input(tokens, max_length, tokenizer):\n",
    "#     # Prepare the input for the model\n",
    "#     encoded_dict = tokenizer.encode_plus(tokens, max_length=max_length, \n",
    "#                                           padding='max_length', truncation=True, \n",
    "#                                           return_tensors='pt')\n",
    "#     return encoded_dict\n",
    "\n",
    "def prepare_data(df, tokenizer):\n",
    "    # Convert the token columns to strings, and then to lists of tokens\n",
    "    df['Content_Tokens'] = df['Content_Tokens'].apply(lambda x: eval(str(x)))\n",
    "    df['Summary_Tokens'] = df['Summary_Tokens'].apply(lambda x: eval(str(x)))\n",
    "    \n",
    "    # Prepare the data for input into the models\n",
    "    df['Content_Input'] = df['Content_Tokens'].apply(prepare_input, args=(512,tokenizer,))\n",
    "    df['Summary_Input'] = df['Summary_Tokens'].apply(prepare_input, args=(128,tokenizer,))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# def prepare_data(df, tokenizer):\n",
    "#     # Prepare the data for input into the models\n",
    "#     df['Content_Tokens'] = df['Content_Tokens'].apply(eval) # convert string representation to list of tokens\n",
    "#     df['Summary_Tokens'] = df['Summary_Tokens'].apply(eval) # convert string representation to list of tokens\n",
    "#     df['Content_Input'] = df['Content_Tokens'].apply(prepare_input, args=(512,tokenizer,))\n",
    "#     df['Summary_Input'] = df['Summary_Tokens'].apply(prepare_input, args=(128,tokenizer,))\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 5: Define a function to score the models\n",
    "# def score_model(model, input1, input2):\n",
    "#     # Generate embeddings for the inputs\n",
    "#     output1 = model(**input1)[1].detach().numpy()\n",
    "#     output2 = model(**input2)[1].detach().numpy()\n",
    "    \n",
    "#     # Calculate the Word Mover's Distance between the embeddings\n",
    "#     wmd = gensim.models.Word2Vec.euclidean_distances(output1, output2)\n",
    "    \n",
    "#     # Calculate the Smooth Inverse Frequency similarity between the embeddings\n",
    "#     sif = cosine_similarity(output1.mean(axis=0, keepdims=True), \n",
    "#                              output2.mean(axis=0, keepdims=True))[0][0]\n",
    "    \n",
    "#     return wmd, sif\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# Step 5: Define a function to score the models\n",
    "def score_model(model, input1, input2):\n",
    "    # Generate embeddings for the inputs\n",
    "    output1 = model(**input1)[0].detach().numpy().mean(axis=1)\n",
    "    output2 = model(**input2)[0].detach().numpy().mean(axis=1)\n",
    "    \n",
    "    # Calculate the Word Mover's Distance between the embeddings\n",
    "    wmd = pairwise_distances(output1, output2, metric='euclidean')\n",
    "    \n",
    "    # Calculate the Smooth Inverse Frequency similarity between the embeddings\n",
    "    sif = cosine_similarity(output1.mean(axis=0, keepdims=True), \n",
    "                             output2.mean(axis=0, keepdims=True))[0][0]\n",
    "    \n",
    "    return wmd, sif\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing MobileBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MobileBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertModel: ['predictions.decoder.bias', 'predictions.LayerNorm.weight', 'predictions.decoder.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.bias', 'predictions.dense.bias']\n",
      "- This IS expected if you are initializing AlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at google/electra-small-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DistilBERT\n",
      "WMD Mean: 4.4856\n",
      "SIF Mean: 0.8400\n",
      "Model: MobileBERT\n",
      "WMD Mean: 2204752.0000\n",
      "SIF Mean: 0.9992\n",
      "Model: ALBERT\n",
      "WMD Mean: 15.5492\n",
      "SIF Mean: 0.8180\n",
      "Model: ELECTRA\n",
      "WMD Mean: 8.3385\n",
      "SIF Mean: 0.3745\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Evaluate the models and compare their scores\n",
    "tokenizer_dict = {\n",
    "    'DistilBERT': DistilBertTokenizer.from_pretrained('distilbert-base-uncased'),\n",
    "    'MobileBERT': MobileBertTokenizer.from_pretrained('google/mobilebert-uncased'),\n",
    "    'ALBERT': AlbertTokenizer.from_pretrained('albert-base-v2'),\n",
    "    # 'TinyBERT': TinyBertTokenizer.from_pretrained('prajjwal1/bert-tiny'),\n",
    "    'ELECTRA': ElectraTokenizer.from_pretrained('google/electra-small-discriminator')\n",
    "}\n",
    "\n",
    "model_dict = {\n",
    "    'DistilBERT': DistilBertModel.from_pretrained('distilbert-base-uncased'),\n",
    "    'MobileBERT': MobileBertModel.from_pretrained('google/mobilebert-uncased'),\n",
    "    'ALBERT': AlbertModel.from_pretrained('albert-base-v2'),\n",
    "    # 'TinyBERT': TinyBertModel.from_pretrained('prajjwal1/bert-tiny'),\n",
    "    'ELECTRA': ElectraModel.from_pretrained('google/electra-small-discriminator')\n",
    "}\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "for model_name in tokenizer_dict.keys():\n",
    "    tokenizer = tokenizer_dict[model_name]\n",
    "    model = model_dict[model_name]\n",
    "    train_df = prepare_data(train_df, tokenizer)\n",
    "    test_df = prepare_data(test_df, tokenizer)\n",
    "    scores = []\n",
    "    for i, row in test_df.iterrows():\n",
    "        content_input = row['Content_Input']\n",
    "        summary_input = row['Summary_Input']\n",
    "        wmd, sif = score_model(model, content_input, summary_input)\n",
    "        scores.append({'WMD': wmd, 'SIF': sif})\n",
    "    results_dict[model_name] = scores\n",
    "\n",
    "# Print the results\n",
    "for model_name, scores in results_dict.items():\n",
    "    wmd_scores = [score['WMD'] for score in scores]\n",
    "    sif_scores = [score['SIF'] for score in scores]\n",
    "    wmd_mean = np.mean(wmd_scores)\n",
    "    sif_mean = np.mean(sif_scores)\n",
    "    print(f'Model: {model_name}')\n",
    "    print(f'WMD Mean: {wmd_mean:.4f}')\n",
    "    print(f'SIF Mean: {sif_mean:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
