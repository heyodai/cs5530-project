{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1 - Data Acquisition and Refinement\n",
    "\n",
    "The goals for Phase 1, per the roadmap in the readme, are as follows:\n",
    "\n",
    "1. Obtain a dataset of news articles that includes the text content as well as a summary of each article. \n",
    "2. Explore the dataset to get a sense of the data, such as the number of articles, length of the articles and summaries, and distribution of topics and keywords.\n",
    "3. Clean and preprocess the data to remove unnecessary characters, punctuation, and stop words. \n",
    "4. Tokenize the text into words or subwords, and create input sequences and output summaries."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal 1: Obtain a Dataset\n",
    "\n",
    "We've obtained a dataset from Kaggle that contains 870,521 articles, each of which has a text content and a summary. The text content is the full article, and the summary is a short version of the article that summarizes the main points.\n",
    "\n",
    "For more information on the dataset, please see the dataset section in `README.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/news_summarization.csv') # expect this step to take about 30 seconds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal 2: Explore the Dataset\n",
    "\n",
    "We've explored the dataset and found the following information:\n",
    "- Total of 870,521 articles\n",
    "- Only 580,013 unique articles\n",
    "\n",
    "The dataset contains the following columns:\n",
    "- `Unnamed: 0` - index, can be ignored\n",
    "- `ID` - unique ID for each article (appears to be a generated UUID)\n",
    "- `Content` - the text content of the article\n",
    "- `Summary` - the summary of the article\n",
    "- `Dataset` - the dataset that the article came from (XSum, CNN/Daily Mail, Multi-News)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Content</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f49ee725a0360aa6881ed1f7999cc531885dd06a</td>\n",
       "      <td>New York police are concerned drones could bec...</td>\n",
       "      <td>Police have investigated criminals who have ri...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>808fe317a53fbd3130c9b7563341a7eea6d15e94</td>\n",
       "      <td>By . Ryan Lipman . Perhaps Australian porn sta...</td>\n",
       "      <td>Porn star Angela White secretly filmed sex act...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98fd67bd343e58bc4e275bbb5a4ea454ec827c0d</td>\n",
       "      <td>This was, Sergio Garcia conceded, much like be...</td>\n",
       "      <td>American draws inspiration from fellow country...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e12b5bd7056287049d9ec98e41dbb287bd19a981</td>\n",
       "      <td>An Ebola outbreak that began in Guinea four mo...</td>\n",
       "      <td>World Health Organisation: 635 infections and ...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b83e8bcfcd51419849160e789b6658b21a9aedcd</td>\n",
       "      <td>By . Associated Press and Daily Mail Reporter ...</td>\n",
       "      <td>A sinkhole opened up at 5:15am this morning in...</td>\n",
       "      <td>CNN/Daily Mail</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         ID  \\\n",
       "0  f49ee725a0360aa6881ed1f7999cc531885dd06a   \n",
       "1  808fe317a53fbd3130c9b7563341a7eea6d15e94   \n",
       "2  98fd67bd343e58bc4e275bbb5a4ea454ec827c0d   \n",
       "3  e12b5bd7056287049d9ec98e41dbb287bd19a981   \n",
       "4  b83e8bcfcd51419849160e789b6658b21a9aedcd   \n",
       "\n",
       "                                             Content  \\\n",
       "0  New York police are concerned drones could bec...   \n",
       "1  By . Ryan Lipman . Perhaps Australian porn sta...   \n",
       "2  This was, Sergio Garcia conceded, much like be...   \n",
       "3  An Ebola outbreak that began in Guinea four mo...   \n",
       "4  By . Associated Press and Daily Mail Reporter ...   \n",
       "\n",
       "                                             Summary         Dataset  \n",
       "0  Police have investigated criminals who have ri...  CNN/Daily Mail  \n",
       "1  Porn star Angela White secretly filmed sex act...  CNN/Daily Mail  \n",
       "2  American draws inspiration from fellow country...  CNN/Daily Mail  \n",
       "3  World Health Organisation: 635 infections and ...  CNN/Daily Mail  \n",
       "4  A sinkhole opened up at 5:15am this morning in...  CNN/Daily Mail  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(df.columns[0], axis=1) # unused index column\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 870521 entries, 0 to 870520\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   ID       814305 non-null  object\n",
      " 1   Content  870487 non-null  object\n",
      " 2   Summary  870521 non-null  object\n",
      " 3   Dataset  870521 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 26.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                870487\n",
       "unique                                               580013\n",
       "top       If you have a picture you would like to share,...\n",
       "freq                                                     25\n",
       "Name: Content, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's find the average article length (in words)\n",
    "# df['Content'].mean()\n",
    "# df['Content'].str.split().apply(len).mean()\n",
    "df['Content'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Content'].str.split().apply(len).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal 3: Clean and Preprocess the Data\n",
    "\n",
    "We've cleaned and preprocessed the data by doing the following:\n",
    "- Removed articles that are duplicates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7cb1b9ae4d417fedf7f40a8eec98f7cfbd359e096bd857395a915f4609834ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
